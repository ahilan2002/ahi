{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20BCE1832\n",
    "    Harini S\n",
    "    WEB MINING LAB\n",
    "    WEEK 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. ii. Apply Run-length Encoding to compress the following Text: Input string is “wwwwwwaaaaadepppppppppp”, then the function should return “w6a5d1e1p10”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w6a5d1e1p01\n"
     ]
    }
   ],
   "source": [
    "def encode(message):\n",
    "    encoded_message = \"\"\n",
    "    i=0\n",
    "    \n",
    "    while (i<= len(message)-1):\n",
    "        count = 1\n",
    "        ch = message[i]\n",
    "        j=i\n",
    "        while (j< len(message)-1):\n",
    "            if (message[j] == message[j+1]):\n",
    "                count=count+1\n",
    "                j=j+1\n",
    "            else:\n",
    "                break\n",
    "        encoded_message=str(count)+ch+encoded_message\n",
    "        i=j+1\n",
    "    return encoded_message\n",
    "encoded_message=encode(\"wwwwwwaaaaadepppppppppp\")\n",
    "print(encoded_message[::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. i. Apply run length encoding for the following string and compress it. “eeeeeeerrrrrrrrrrrrrrrrttttttttttttttiiiiiiiifffffeft”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7e16r14t8i5f1e1f1t\n"
     ]
    }
   ],
   "source": [
    "def encode(message):\n",
    "    encoded_message = \"\"\n",
    "    i=0\n",
    "    \n",
    "    while (i<= len(message)-1):\n",
    "        count = 1\n",
    "        ch = message[i]\n",
    "        j=i\n",
    "        while (j< len(message)-1):\n",
    "            if (message[j] == message[j+1]):\n",
    "                count=count+1\n",
    "                j=j+1\n",
    "            else:\n",
    "                break\n",
    "        encoded_message=encoded_message+str(count)+ch\n",
    "        i=j+1\n",
    "    return encoded_message\n",
    "encoded_message=encode(\"eeeeeeerrrrrrrrrrrrrrrrttttttttttttttiiiiiiiifffffeft\")\n",
    "print(encoded_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Consider the following Inverted Index File with Terms, Occurrences and Posting List\n",
    "\n",
    "Term      Occurrences   Posting List (Doc ids)\n",
    "\n",
    "Samsung   233           34544, 34574, 35569, …\n",
    "\n",
    "Airtel    12            12, 17, 25, 148, 156, 159, 172, …\n",
    "\n",
    "Mercury   15            1, 2, 3, 7, 9, 10, …\n",
    "\n",
    "Venus     12            23, 45, 78, 122, 145, …\n",
    "\n",
    "Fiber     6             1, 3, 5, 7, 19, 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# i. Apply Binary coding for term “Mercury” (apply for all doc ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00001', '00010', '00011', '00111', '01001', '01010']\n"
     ]
    }
   ],
   "source": [
    "def to_binary(num):\n",
    "    binary=bin(num) [2:]\n",
    "    return binary.zfill(5)\n",
    "\n",
    "doc_ids = [1,2,3,7,9,10]\n",
    "binary_representation = [to_binary(id) for id in doc_ids]\n",
    "print(binary_representation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ii. Apply Unary coding for term “Fiber”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unary encoding for term 'Fiber': ['10', '1110', '111110', '11111110', '11111111111111111110', '111111111111111111110']\n"
     ]
    }
   ],
   "source": [
    "def unary_encode(num):\n",
    "    return \"1\" *num + \"0\"\n",
    "\n",
    "doc_ids = [1,3,5,7,19,20]\n",
    "encoded_representation = [unary_encode(id) for id in doc_ids]\n",
    "print(\"Unary encoding for term 'Fiber':\", encoded_representation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iii. Apply Elias Gamma Encoding for term “Airtel”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elias gamma encoding for term 'Airtel': ['11101101', '1111010010', '1111011010', '1111111010010101', '1111111010011101', '1111111010100000', '1111111010101101']\n"
     ]
    }
   ],
   "source": [
    "def elias_gamma_encode(num):\n",
    "    binary=bin(num+1)[2:]\n",
    "    length=len(binary)\n",
    "    prefix=\"1\" * length + \"0\"\n",
    "    return prefix[1:]+binary\n",
    "\n",
    "doc_ids=[12,17,25,148,156,159,172]\n",
    "encoded_representation=[elias_gamma_encode(id) for id in doc_ids]\n",
    "print(\"Elias gamma encoding for term 'Airtel':\",encoded_representation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iv. Apply Elias Delta Encoding and Decoding for “Mercury”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elias delta encoding for term 'Mercury': ['101', '11010', '11011', '1110111', '111101001', '111101010']\n",
      "Elias delta decoding for term 'Mercury': [1, 2, 3, 7, 9, 10]\n"
     ]
    }
   ],
   "source": [
    "def elias_delta_encode(num):\n",
    "    binary=bin(num)[2:]\n",
    "    length=len(binary)\n",
    "    prefix=\"1\" * length + \"0\"\n",
    "    return prefix+binary\n",
    "\n",
    "def elias_delta_decode(encoded):\n",
    "    length=encoded.index(\"0\")\n",
    "    prefix=encoded[:length+1]\n",
    "    binary=encoded[length+1:]\n",
    "    num=int(binary,2)\n",
    "    return num\n",
    "\n",
    "doc_ids=[1,2,3,7,9,10]\n",
    "encoded_representation=[elias_delta_encode(id) for id in doc_ids]\n",
    "print(\"Elias delta encoding for term 'Mercury':\",encoded_representation)\n",
    "\n",
    "decoded_representation=[elias_delta_decode(encoded) for encoded in encoded_representation]\n",
    "print(\"Elias delta decoding for term 'Mercury':\",decoded_representation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# v. Apply Elias Delta Encoding for term “Venus”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elias delta encoding for term 'Venus': ['11111010111', '1111110101101', '111111101001110', '111111101111010', '11111111010010001']\n"
     ]
    }
   ],
   "source": [
    "def elias_delta_encode(num):\n",
    "    binary=bin(num)[2:]\n",
    "    length=len(binary)\n",
    "    prefix=\"1\" * length + \"0\"\n",
    "    return prefix+binary\n",
    "\n",
    "doc_ids=[23,45,78,122,145]\n",
    "encoded_representation=[elias_delta_encode(id) for id in doc_ids]\n",
    "print(\"Elias delta encoding for term 'Venus':\",encoded_representation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vi. Apply Elias Delta Decoding for “00101001”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "def elias_delta_decoding(x):\n",
    "    x=list(x)\n",
    "    L=0\n",
    "    while True:\n",
    "        if not x[L]=='0':\n",
    "            break\n",
    "        L=L+1\n",
    "    #reading L more bits and dropping all\n",
    "    x=x[2*L+1:]\n",
    "    \n",
    "    #prepending with 1 in MSB\n",
    "    x.reverse()\n",
    "    x.insert(0,'1')\n",
    "    n=0\n",
    "    \n",
    "    #converting bin to int\n",
    "    for i in range(len(x)):\n",
    "        if x[i]=='1':\n",
    "            n=n+math.pow(2,i)\n",
    "    return int(n)\n",
    "\n",
    "x='00101001'\n",
    "print(elias_delta_decoding(x))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vii. Apply Variable Byte Encoding for “Samsung”. (Use doc ids gap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable byte encoding for term 'Samsung': [[30], [7, 227]]\n"
     ]
    }
   ],
   "source": [
    "def variable_byte_encode(num):\n",
    "    representation=[]\n",
    "    while num>=128:\n",
    "        representation.append(num% 128+128)\n",
    "        num//=128\n",
    "    representation.append(num)\n",
    "    return representation[::-1]\n",
    "\n",
    "#doc ids gap\n",
    "doc_ids=[34544,34574,35569]\n",
    "gaps=[doc_ids[i]-doc_ids[i-1]for i in range(1,len(doc_ids))]\n",
    "encoded_representation=[variable_byte_encode(gap) for gap in gaps]\n",
    "print(\"Variable byte encoding for term 'Samsung':\",encoded_representation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement Signature File for the following document:\n",
    "\n",
    "Document : This is a text. A text has many words. Words are made from letters. The text is made of letters. Made many words letters text. Letters are text.\n",
    "\n",
    "Hint: build blocks accordingly.\n",
    "\n",
    "Search for the following keywords:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# i. Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_signature_file(document,keywords):\n",
    "    block_size=4\n",
    "    blocks=[0]*block_size\n",
    "    for keyword in keywords:\n",
    "        for i, word in enumerate(document.split()):\n",
    "            if word==keyword:\n",
    "                blocks[i%block_size]=1<<(i//block_size)\n",
    "        return blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signature file: [0, 0, 0, 0]\n",
      "Keyword 'Text' found at index(es): []\n"
     ]
    }
   ],
   "source": [
    "document=\"This is a text. A text has many words. Words are made from letters. The text is made of letters. Made many words letters text. Letters are text.\"\n",
    "keywords=[\"Text\"]\n",
    "signature_file=build_signature_file(document,keywords)\n",
    "print(\"Signature file:\",signature_file)\n",
    "\n",
    "def search_keyword(document,keyword,signature_file):\n",
    "    block_size=4\n",
    "    keyword_indexes=[]\n",
    "    for i, word in enumerate(document.split()):\n",
    "        if word==keyword:\n",
    "                block=i//block_size\n",
    "                if signature_file[block]&(1<<(i%block_size))!=0:\n",
    "                    keyword_indexes.append(i)\n",
    "    return keyword_indexes\n",
    "\n",
    "search_result=search_keyword(document,\"Text\",signature_file)\n",
    "print(\"Keyword 'Text' found at index(es):\",search_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ii. Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyword 'Words' found in block(s): [2]\n"
     ]
    }
   ],
   "source": [
    "document=\"This is a text. A text has many words. Words are made from letters. The text is made of letters. Made many words letters text. Letters are text.\"\n",
    "#build blocks of 4 words each\n",
    "blocks=[]\n",
    "start=0\n",
    "end=4\n",
    "while end<=len(document.split()):\n",
    "    blocks.append(\" \".join(document.split()[start:end]))\n",
    "    start=end\n",
    "    end+=4\n",
    "    \n",
    "    \n",
    "#create a dictionary of words and their block index\n",
    "signature_file={}\n",
    "for i, block in enumerate(blocks):\n",
    "    for word in block.split():\n",
    "        if word not in signature_file:\n",
    "            signature_file[word]=[i]\n",
    "        else:\n",
    "            signature_file[word].append(i)\n",
    "            \n",
    "#search function\n",
    "def search_keyword(document,keyword,signature_file):\n",
    "    if keyword in signature_file:\n",
    "        return signature_file[keyword]\n",
    "    return[]\n",
    "\n",
    "#search for keyword \"Words\"\n",
    "search_result=search_keyword(document,\"Words\",signature_file)\n",
    "print(\"Keyword 'Words' found in block(s):\",search_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iii) Made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positions of keyword 'Made' in the document: [20]\n"
     ]
    }
   ],
   "source": [
    "document=\"This is a text. A text has many words. Words are made from letters. The text is made of letters. Made many words letters text. Letters are text.\"\n",
    "#create a list to store the position of keyword \"made\" in the document\n",
    "made_positions=[]\n",
    "#split the document into words and find the position of \"made\" in the document\n",
    "words=document.split()\n",
    "for i, word in enumerate(words):\n",
    "    if word==\"Made\":\n",
    "        made_positions.append(i)\n",
    "        \n",
    "        \n",
    "#print the position of keyword \"made\" in the document\n",
    "print(\"Positions of keyword 'Made' in the document:\",made_positions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iv)Letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positions of keyword 'Letters' in the document: [25]\n"
     ]
    }
   ],
   "source": [
    "document=\"This is a text. A text has many words. Words are made from letters. The text is made of letters. Made many words letters text. Letters are text.\"\n",
    "#create a list to store the position of keyword \"Letters\" in the document\n",
    "letters_positions=[]\n",
    "#split the document into words and find the position of \"Letters\" in the document\n",
    "words=document.split()\n",
    "for i, word in enumerate(words):\n",
    "    if word==\"Letters\":\n",
    "        letters_positions.append(i)\n",
    "        \n",
    "        \n",
    "#print the position of keyword \"Letters\" in the document\n",
    "print(\"Positions of keyword 'Letters' in the document:\",letters_positions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
